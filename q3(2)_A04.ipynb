{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q3(2)-A04.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2KId6dWNesO5eKsCWdMmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamalSanjaya/CV_A04/blob/main/q3(2)_A04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W8QH9qiDf6r"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-_6NnnDmry",
        "outputId": "0981b9e4-0f3a-44dc-fe56-22b281e956b5"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3uLXo_tDyJ6"
      },
      "source": [
        "x_train_copy , x_test_copy = x_train.copy() , x_test.copy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJFHVrbmD1F_"
      },
      "source": [
        "K = len(np.unique(y_train)) # Classes\n",
        "Ntr = x_train.shape[0]\n",
        "\n",
        "Nte = x_test.shape[0]\n",
        "Din = 3072 # CIFAR10\n",
        "# Din = 784 # MINIST\n",
        "\n",
        "# Normalize pixel values\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
        "x_train = np.reshape(x_train,(Ntr,Din))\n",
        "x_test = np.reshape(x_test,(Nte,Din))\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_katMPk7D4zS"
      },
      "source": [
        "std=1e-5\n",
        "H=200\n",
        "w1 = std*np.random.randn(Din, H)\n",
        "b1 = np.zeros(H)\n",
        "w2 = std*np.random.randn(H, K)\n",
        "b2 = np.zeros(K)\n",
        "\n",
        "batch_size = 500\n",
        "iterations = 300\n",
        "lr = 1.4e-2\n",
        "lr_decay= 0.999\n",
        "reg = 5e-6\n",
        "loss_history = []\n",
        "train_acc_history = []\n",
        "val_acc_history = []\n",
        "seed = 0\n",
        "#rng = np.random.default_rng(seed=seed)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF0edSawD6r9"
      },
      "source": [
        "def trainAcc(true,predict):\n",
        "  return 1.0 - 1.0/(batch_size*K)*np.abs(np.argmax(true , axis=1) - np.argmax(predict , axis=1) ).sum()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH9eS-K5EBNJ"
      },
      "source": [
        "def backprogation(true,predict,H):\n",
        "\n",
        "  dL_dyt = 1./batch_size*2.0*(predict-true)\n",
        "  dw2     = H.T.dot(dL_dyt) + reg*w2\n",
        "  db2     = dL_dyt.sum(axis=0)\n",
        "  dh      = dL_dyt.dot(w2.T)\n",
        "  dw1     = x.T.dot(dh * H*(1-H)) +  reg*w1\n",
        "  db1     =  (dh * H*(1-H)).sum(axis=0)\n",
        "\n",
        "  return dw1,db1,dw2,db2\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWf7jk4lEDA8",
        "outputId": "040ee5a2-c64e-4f08-8c56-15447cc271fe"
      },
      "source": [
        "\n",
        "## Stochatic Gradient descent  (sample size = 500)\n",
        "\n",
        "for t in range(iterations):\n",
        "  batch_indices = np.random.choice(Ntr,batch_size)\n",
        "  x = x_train[batch_indices]\n",
        "  y = y_train[batch_indices]\n",
        "  h = 1.0/(1.0 + np.exp( -(x.dot(w1) + b1) ))\n",
        "  y_pred = h.dot(w2) + b2\n",
        "  loss  = 1./batch_size*np.square(y_pred - y).sum()  + reg*(np.sum(w1*w1) + np.sum(w2*w2)) \n",
        "  loss_history.append(loss)\n",
        "\n",
        "  if t%10 == 0:\n",
        "    Acc = trainAcc(y, y_pred)\n",
        "    print(\"Loss : \" , loss , \" | Accuray :\", Acc)\n",
        "\n",
        "  dw1,db1,dw2,db2 = backprogation(y,y_pred,h)\n",
        "\n",
        "  w1 -= lr*dw1\n",
        "  b1 -= lr*db1\n",
        "  w2 -= lr*dw2\n",
        "  b2 -= lr*db2\n",
        "  lr *= lr_decay\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss :  0.9999879270042232  | Accuray : 0.6522\n",
            "Loss :  0.9078974794005481  | Accuray : 0.751\n",
            "Loss :  0.9057444841079582  | Accuray : 0.5633999999999999\n",
            "Loss :  0.9116932308844226  | Accuray : 0.6788\n",
            "Loss :  0.8998911053873481  | Accuray : 0.7694\n",
            "Loss :  0.9023797967677646  | Accuray : 0.6828\n",
            "Loss :  0.906487281595115  | Accuray : 0.6496\n",
            "Loss :  0.9017893178023062  | Accuray : 0.6958\n",
            "Loss :  0.9034632849231167  | Accuray : 0.756\n",
            "Loss :  0.9063413067651458  | Accuray : 0.556\n",
            "Loss :  0.9005467883063166  | Accuray : 0.5704\n",
            "Loss :  0.9030031386865875  | Accuray : 0.7432\n",
            "Loss :  0.9016369754356877  | Accuray : 0.7686\n",
            "Loss :  0.9010309658947782  | Accuray : 0.5448\n",
            "Loss :  0.9027009120886584  | Accuray : 0.7604\n",
            "Loss :  0.9025928731189252  | Accuray : 0.625\n",
            "Loss :  0.8993662794830798  | Accuray : 0.6392\n",
            "Loss :  0.9039206397769372  | Accuray : 0.7314\n",
            "Loss :  0.9028746562636276  | Accuray : 0.6344\n",
            "Loss :  0.9018481759514336  | Accuray : 0.7408\n",
            "Loss :  0.9019300848158107  | Accuray : 0.5451999999999999\n",
            "Loss :  0.9028454075011794  | Accuray : 0.552\n",
            "Loss :  0.9017606314190311  | Accuray : 0.7061999999999999\n",
            "Loss :  0.9050659764159057  | Accuray : 0.6884\n",
            "Loss :  0.9016997907188363  | Accuray : 0.7043999999999999\n",
            "Loss :  0.9003946469760465  | Accuray : 0.7494000000000001\n",
            "Loss :  0.905641403983912  | Accuray : 0.7363999999999999\n",
            "Loss :  0.901797216734048  | Accuray : 0.5691999999999999\n",
            "Loss :  0.9036580989228876  | Accuray : 0.5389999999999999\n",
            "Loss :  0.9010838916206741  | Accuray : 0.6428\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}